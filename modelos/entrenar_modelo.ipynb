{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f990cb5",
   "metadata": {},
   "source": [
    "**Librerias y configuracion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87799a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib\n",
    "import re\n",
    "import unicodedata\n",
    "import snowballstemmer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a7060",
   "metadata": {},
   "source": [
    "**Funcion para limpiar texto con Steamming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c59676",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = snowballstemmer.stemmer('spanish')\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    # Pasar a min√∫sculas\n",
    "    texto = texto.lower()\n",
    "    # Eliminar tildes\n",
    "    texto = ''.join(c for c in unicodedata.normalize('NFD', texto)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "    # Eliminar signos de puntuaci√≥n\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    # Tokenizar separando por espacios\n",
    "    tokens = texto.split()\n",
    "    texto_stem = ' '.join([stemmer.stemWord(token) for token in tokens])\n",
    "    return texto_stem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a01890",
   "metadata": {},
   "source": [
    "**Generacion de Log con preguntas desconocias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c786ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para registrar preguntas desconocidas agrupadas por d√≠a\n",
    "def registrar_desconocida(pregunta_usuario):\n",
    "    hoy = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    log_path = \"log_desconocidas.txt\"\n",
    "\n",
    "    try:\n",
    "        with open(log_path, \"r\") as f:\n",
    "            contenido = f.read()\n",
    "    except FileNotFoundError:\n",
    "        contenido = \"\"\n",
    "\n",
    "    if hoy not in contenido:\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(f\"\\nüìÖ {hoy}\\n\")\n",
    "\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(f\"- {pregunta_usuario}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a3eca3",
   "metadata": {},
   "source": [
    "**Cargar y limpiar el dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "dataset = pd.read_csv(\"datos/data_set.csv\", skipinitialspace=True)\n",
    "\n",
    "# Limpiar preguntas\n",
    "dataset['Pregunta_limpia'] = dataset['Pregunta'].apply(limpiar_texto)\n",
    "\n",
    "# Separar preguntas limpias y respuestas\n",
    "preguntas = dataset['Pregunta_limpia'].values\n",
    "respuestas = dataset['Respuesta'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4aa30f",
   "metadata": {},
   "source": [
    "**Vectorizacion y entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ecda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizar\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preguntas)\n",
    "\n",
    "# Entrenar modelo\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(X, respuestas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dcc8f5",
   "metadata": {},
   "source": [
    "**Guardar modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo y vectorizer\n",
    "joblib.dump(modelo, \"modelo_entrenado.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39668be",
   "metadata": {},
   "source": [
    "**Funcion de prediccion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_respuesta(pregunta_usuario):\n",
    "    pregunta_limpia = limpiar_texto(pregunta_usuario)\n",
    "    pregunta_vectorizada = vectorizer.transform([pregunta_limpia])\n",
    "    probas = modelo.predict_proba(pregunta_vectorizada)[0]\n",
    "    indice_max = probas.argmax()\n",
    "    confianza = probas[indice_max]\n",
    "    \n",
    "    rango_confianza = 0.3\n",
    "    \n",
    "   # Configuraci√≥n del cuadro informativo\n",
    "    ancho = 90\n",
    "    linea_superior = \"‚ïî\" + \"‚ïê\" * (ancho - 2) + \"‚ïó\"\n",
    "    linea_inferior = \"‚ïö\" + \"‚ïê\" * (ancho - 2) + \"‚ïù\"\n",
    "    linea_separadora = \"‚ï†\" + \"‚ïê\" * (ancho - 2) + \"‚ï£\"\n",
    "    linea_divisoria = \"‚ïë\" + \"‚îÄ\" * (ancho - 2) + \"‚ïë\"\n",
    "\n",
    "    # Contenido\n",
    "    cabecera = \"ANALISIS DEL MODELO SEGUN PROMPT\"\n",
    "    items = [\n",
    "        f\"Cantidad de pruebas en el dataset: {len(preguntas)}\",\n",
    "        f\"Cantidad de palabras en el vocabulario: {len(vectorizer.get_feature_names_out())}\",\n",
    "        f\"Probabilidad de cada clase: {probas}\",\n",
    "        f\"Clase con mayor probabilidad: {confianza}\",\n",
    "        f\"Nivel de confianza: {rango_confianza}\",\n",
    "        \n",
    "        f\"Categor√≠a elegida: {modelo.classes_[indice_max]}\",\n",
    "    ]\n",
    "\n",
    "    # Imprimir cuadro\n",
    "    print(linea_superior)\n",
    "    print(\"‚ïë\" + cabecera.center(ancho - 2) + \"‚ïë\")\n",
    "    print(linea_separadora)\n",
    "    for i, item in enumerate(items):\n",
    "        print(\"‚ïë \" + item.ljust(ancho - 3) + \"‚ïë\")\n",
    "        if i < len(items) - 1:\n",
    "            print(linea_divisoria)\n",
    "    print(linea_inferior)\n",
    "\n",
    "    if confianza < rango_confianza:\n",
    "        registrar_desconocida(pregunta_usuario)\n",
    "        return \"No entend√≠ lo que me preguntaste, ¬øme lo pod√©s repetir?\"\n",
    "    return modelo.classes_[indice_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8e13c",
   "metadata": {},
   "source": [
    "**Prueba interactiva en vivo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c90111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacci√≥n en bucle\n",
    "while True:\n",
    "    pregunta_usuario = input(\"Podes preguntarme algo o podes escribir 'salir': \")\n",
    "    if pregunta_usuario.lower() == \"salir\":\n",
    "        break\n",
    "    print(obtener_respuesta(pregunta_usuario))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
